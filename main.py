#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
KoemojiAuto - è‡ªå‹•æ–‡å­—èµ·ã“ã—ã‚·ã‚¹ãƒ†ãƒ 
éŸ³å£°ãƒ»å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—ã‚’è‡ªå‹•å‡¦ç†
"""

import os
import time
import json
import logging
from pathlib import Path
from datetime import datetime, time as datetime_time
import psutil
import platform

# OSåˆ¤å®š  
IS_WINDOWS = platform.system() == 'Windows'

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
from logging.handlers import RotatingFileHandler

# ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®è¨­å®šï¼ˆåˆ†å˜ä½ã¾ã§è¡¨ç¤ºï¼‰
log_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M')

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆ10MBã§ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€5ãƒ•ã‚¡ã‚¤ãƒ«ä¿æŒï¼‰
file_handler = RotatingFileHandler(
    "koemoji.log",
    maxBytes=10*1024*1024,  # 10MB
    backupCount=5           # 5ãƒ•ã‚¡ã‚¤ãƒ«ä¿æŒ
)
file_handler.setFormatter(log_formatter)

# ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
console_handler = logging.StreamHandler()
console_handler.setFormatter(log_formatter)

# ãƒ«ãƒ¼ãƒˆãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    handlers=[file_handler, console_handler],
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M'
)

# å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒ­ã‚°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚‚çµ±ä¸€
for handler in logging.root.handlers:
    handler.setFormatter(log_formatter)

logger = logging.getLogger("KoemojiAuto")

class KoemojiProcessor:
    def __init__(self, config_path="config.json"):
        """åˆæœŸåŒ–"""
        self.config_path = config_path
        self.load_config()
        self.processing_queue = []
        self.processed_files = set()
        
        # å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«è¨˜éŒ²ã®èª­ã¿è¾¼ã¿
        self.processed_history_path = Path("processed_files.json")
        self.load_processed_history()
        
        # å‡¦ç†ä¸­ã®ãƒ•ã‚¡ã‚¤ãƒ«
        self.files_in_process = set()
        
        # Whisperãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._whisper_model = None
        self._model_config = None
        
        # æ—¥ä»˜ã”ã¨ã®å‡¦ç†çµ±è¨ˆï¼ˆãƒ­ã‚°ã‹ã‚‰å–å¾—ã™ã‚‹ãŸã‚ãƒ¡ãƒ¢ãƒªä¸Šã®ç®¡ç†ã¯ä¸è¦ï¼‰
        # self.daily_stats = {}
        # self._ensure_daily_stats()  # ä»Šæ—¥ã®çµ±è¨ˆã‚’åˆæœŸåŒ–
    
    def load_config(self):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        try:
            if not os.path.exists(self.config_path):
                # åˆå›ä½¿ç”¨æ™‚ï¼šãƒ•ã‚©ãƒ«ãƒ€æŒ‡å®šã‚’æ±‚ã‚ã‚‹
                print("åˆå›è¨­å®šã‚’è¡Œã„ã¾ã™ã€‚")
                
                # å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®è¨­å®š
                while True:
                    input_folder = input("å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip()
                    if input_folder:
                        input_folder = os.path.expanduser(input_folder)
                        break
                    print("å…¥åŠ›ãŒå¿…è¦ã§ã™ã€‚")
                
                # å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®è¨­å®š
                while True:
                    output_folder = input("å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip()
                    if output_folder:
                        output_folder = os.path.expanduser(output_folder)
                        break
                    print("å…¥åŠ›ãŒå¿…è¦ã§ã™ã€‚")
                
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½œæˆ
                self.config = {
                    "input_folder": input_folder,
                    "output_folder": output_folder,
                    "process_start_time": "19:00",
                    "process_end_time": "07:00",
                    "scan_interval_minutes": 30,
                    "max_concurrent_files": 3,
                    "whisper_model": "large",
                    "language": "ja",
                    "compute_type": "int8",
                    "max_cpu_percent": 95
                }
                # è¨­å®šã‚’ä¿å­˜
                with open(self.config_path, 'w', encoding='utf-8') as f:
                    json.dump(self.config, f, indent=2, ensure_ascii=False)
                logger.info(f"âš™ï¸  è¨­å®šã‚’ä½œæˆã—ã¾ã—ãŸ: {self.config_path}")
                print(f"\nè¨­å®šãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ: {self.config_path}")
            else:
                # æ—¢å­˜ã®è¨­å®šã‚’èª­ã¿è¾¼ã¿
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    self.config = json.load(f)
                logger.info(f"âš™ï¸  è¨­å®šã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {self.config_path}")
                
                # è¨­å®šå€¤ã®æ¤œè¨¼
                self.validate_config()
                
            # å…¥åŠ›ãƒ»å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ç¢ºèªã¨ä½œæˆ
            for folder_key in ["input_folder", "output_folder"]:
                folder_path = self.config.get(folder_key)
                if not os.path.exists(folder_path):
                    os.makedirs(folder_path, exist_ok=True)
                    logger.info(f"ğŸ“ {folder_key}ã‚’ä½œæˆã—ã¾ã—ãŸ: {folder_path}")
                    
            # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã®ä½œæˆ
            if not os.path.exists("reports"):
                os.makedirs("reports", exist_ok=True)
                logger.info("ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã¾ã—ãŸ: reports")
                    
        except Exception as e:
            logger.error(f"âŒ è¨­å®šã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            # æœ€å°é™ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
            self.config = {
                "input_folder": "input",
                "output_folder": "output",
                "process_start_time": "19:00",
                "process_end_time": "07:00",
                "max_concurrent_files": 1,
                "whisper_model": "tiny",
                "language": "ja"
            }
    
    def validate_config(self):
        """è¨­å®šå€¤ã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡ç´ åŒ–ç‰ˆï¼‰"""
        # å¿…é ˆé …ç›®ã®ã¿ãƒã‚§ãƒƒã‚¯
        required_fields = ["input_folder", "output_folder", "whisper_model", "language"]
        missing = [f for f in required_fields if f not in self.config]
        if missing:
            raise ValueError(f"å¿…é ˆè¨­å®šãŒä¸è¶³: {missing}")
        
        # ä¸æ­£ãªå€¤ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ç½®æ›
        defaults = {
            "process_start_time": "19:00",
            "process_end_time": "07:00",
            "scan_interval_minutes": 30,
            "max_concurrent_files": 3,
            "max_cpu_percent": 95,
            "continuous_mode": False,
            "compute_type": "int8"
        }
        for key, default in defaults.items():
            if key not in self.config:
                self.config[key] = default
    
    
    # ä»¥ä¸‹ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ãƒ­ã‚°ãƒ™ãƒ¼ã‚¹ã®é›†è¨ˆã«ç§»è¡Œã—ãŸãŸã‚ä¸è¦
    # def _ensure_daily_stats(self):
    #     """ä»Šæ—¥ã®çµ±è¨ˆã‚¨ãƒ³ãƒˆãƒªã‚’ç¢ºä¿"""
    #     today = datetime.now().strftime("%Y-%m-%d")
    #     if today not in self.daily_stats:
    #         self.daily_stats[today] = {
    #             "queued": 0,
    #             "processed": 0,
    #             "failed": 0,
    #             "total_duration": 0,
    #             "date": today
    #         }
    
    # def record_stat(self, stat_type, value=1):
    #     """çµ±è¨ˆã‚’è¨˜éŒ²ï¼ˆæ—¥ä»˜ã”ã¨ï¼‰"""
    #     self._ensure_daily_stats()
    #     today = datetime.now().strftime("%Y-%m-%d")
    #     if stat_type in self.daily_stats[today]:
    #         self.daily_stats[today][stat_type] += value
    
    def load_processed_history(self):
        """å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å±¥æ­´ã‚’èª­ã¿è¾¼ã‚€"""
        try:
            if self.processed_history_path.exists():
                with open(self.processed_history_path, 'r', encoding='utf-8') as f:
                    self.processed_files = set(json.load(f))
            else:
                self.processed_files = set()
        except Exception as e:
            logger.error(f"âŒ å‡¦ç†æ¸ˆã¿å±¥æ­´ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            self.processed_files = set()
    
    def save_processed_history(self):
        """å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®å±¥æ­´ã‚’ä¿å­˜ã™ã‚‹"""
        try:
            with open(self.processed_history_path, 'w', encoding='utf-8') as f:
                json.dump(list(self.processed_files), f)
        except Exception as e:
            logger.error(f"âŒ å‡¦ç†æ¸ˆã¿å±¥æ­´ã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_end_time(self):
        """çµ‚äº†æ™‚åˆ»ã‚’å–å¾—"""
        end_time_str = self.config.get("process_end_time", "07:00")
        hour, minute = map(int, end_time_str.split(":"))
        return datetime_time(hour, minute)
    
    def scan_and_queue_files(self):
        """å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ """
        try:
            logger.debug("å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€ã®ã‚¹ã‚­ãƒ£ãƒ³ã‚’é–‹å§‹ã—ã¾ã™")
            
            input_folder = self.config.get("input_folder")
            if not os.path.exists(input_folder):
                logger.warning(f"å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {input_folder}")
                os.makedirs(input_folder, exist_ok=True)
                return
            
            # ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­
            media_extensions = ('.mp3', '.mp4', '.wav', '.m4a', '.mov', '.avi', '.flac', '.ogg', '.aac')
            
            # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º
            new_files = []
            for file in os.listdir(input_folder):
                file_path = os.path.join(input_folder, file)
                
                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ã‚¹ã‚­ãƒƒãƒ—
                if os.path.isdir(file_path):
                    continue
                
                # å¯¾è±¡æ‹¡å¼µå­ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å‡¦ç†
                if not file.lower().endswith(media_extensions):
                    continue
                
                # æ—¢ã«å‡¦ç†æ¸ˆã¿ã¾ãŸã¯å‡¦ç†ä¸­ã€ã‚­ãƒ¥ãƒ¼æ¸ˆã¿ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—
                file_id = f"{file}_{os.path.getsize(file_path)}"
                if file_id in self.processed_files or file_path in self.files_in_process or any(f["path"] == file_path for f in self.processing_queue):
                    continue
                
                new_files.append(file_path)
            
            if not new_files:
                logger.debug("æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“")
                return
            
            # ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
            for file_path in new_files:
                file_name = os.path.basename(file_path)
                file_size = os.path.getsize(file_path)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
                file_info = {
                    "path": file_path,
                    "name": file_name,
                    "size": file_size,
                    "queued_at": datetime.now().isoformat()
                }
                
                self.processing_queue.append(file_info)
                logger.info(f"â• ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ : {file_name}")
                
                # çµ±è¨ˆã‚’è¨˜éŒ²ï¼ˆãƒ­ã‚°ã‹ã‚‰å–å¾—ã™ã‚‹ãŸã‚ä¸è¦ï¼‰
                # self.record_stat("queued")
            
            logger.info(f"ğŸ“‹ ç¾åœ¨ã®ã‚­ãƒ¥ãƒ¼: {len(self.processing_queue)}ä»¶")
            
        except Exception as e:
            logger.error(f"âŒ ã‚­ãƒ¥ãƒ¼ã‚¹ã‚­ãƒ£ãƒ³ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
    def process_queued_files(self):
        """ã‚­ãƒ¥ãƒ¼ã«ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†"""
        try:
            if not self.processing_queue:
                logger.debug("å‡¦ç†ã™ã¹ããƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“")
                return
            
            # åŒæ™‚å‡¦ç†æ•°ã‚’ç¢ºèª
            max_concurrent = self.config.get("max_concurrent_files", 3)
            current_running = len(self.files_in_process)
            available_slots = max(0, max_concurrent - current_running)
            
            if available_slots <= 0:
                logger.debug("åŒæ™‚å‡¦ç†æ•°ã®ä¸Šé™ã«é”ã—ã¦ã„ã¾ã™")
                return
            
            # ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³ã‚’ç¢ºèª
            cpu_percent = psutil.cpu_percent()
            max_cpu = self.config.get("max_cpu_percent", 95)
            
            if cpu_percent > max_cpu:
                logger.info(f"â¸ï¸  CPUä½¿ç”¨ç‡ãŒé«˜ã™ãã‚‹ãŸã‚ã€å‡¦ç†ã‚’å»¶æœŸã—ã¾ã™: {cpu_percent}%")
                return
            
            # å‡¦ç†ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’æ±ºå®š
            files_to_process = self.processing_queue[:available_slots]
            
            # Whisperãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
            model_size = self.config.get("whisper_model", "large")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
            for file_info in files_to_process:
                file_path = file_info["path"]
                # ã‚­ãƒ¥ãƒ¼ã‹ã‚‰å‰Šé™¤
                self.processing_queue = [f for f in self.processing_queue if f["path"] != file_path]
                
                # å‡¦ç†é–‹å§‹
                self.process_file(file_path, model_size)
        
        except Exception as e:
            logger.error(f"âŒ ã‚­ãƒ¥ãƒ¼å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
    def process_file(self, file_path, model_size=None):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹"""
        start_time = time.time()
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
            if not os.path.exists(file_path):
                logger.warning(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {file_path}")
                return
            
            # å‡¦ç†ä¸­ãƒªã‚¹ãƒˆã«è¿½åŠ 
            self.files_in_process.add(file_path)
            file_name = os.path.basename(file_path)
            logger.info(f"ğŸ”„ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–‹å§‹: {file_name} (ãƒ¢ãƒ‡ãƒ«: {model_size})")
            
            # æ–‡å­—èµ·ã“ã—å‡¦ç†ã‚’å®Ÿè¡Œ
            transcription = self.transcribe_audio(file_path, model_size)
            
            if transcription:
                # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç”Ÿæˆ
                output_folder = self.config.get("output_folder")
                output_file = os.path.join(
                    output_folder, 
                    f"{os.path.splitext(file_name)[0]}.txt"
                )
                
                # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
                os.makedirs(output_folder, exist_ok=True)
                
                # çµæœã‚’ä¿å­˜
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(transcription)
                
                # å‡¦ç†æ™‚é–“ã‚’è¨ˆç®—
                processing_time = time.time() - start_time
                logger.info(f"âœ… æ–‡å­—èµ·ã“ã—å®Œäº†: {file_name} -> {output_file} (å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’)")
                
                # å‡¦ç†æ¸ˆã¿ãƒªã‚¹ãƒˆã«è¿½åŠ 
                file_id = f"{file_name}_{os.path.getsize(file_path)}"
                self.processed_files.add(file_id)
                self.save_processed_history()
                
                # çµ±è¨ˆã‚’è¨˜éŒ²ï¼ˆãƒ­ã‚°ã‹ã‚‰å–å¾—ã™ã‚‹ãŸã‚ä¸è¦ï¼‰
                # self.record_stat("processed")
                # self.record_stat("total_duration", processing_time)
                
                # é€šçŸ¥
                self.send_notification(
                    "âœ… Koemojiæ–‡å­—èµ·ã“ã—å®Œäº†",
                    f"ãƒ•ã‚¡ã‚¤ãƒ«: {file_name}\nå‡ºåŠ›: {output_file}\nå‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’"
                )
            else:
                logger.error(f"âŒ æ–‡å­—èµ·ã“ã—å¤±æ•—: {file_name}")
                # çµ±è¨ˆã‚’è¨˜éŒ²ï¼ˆãƒ­ã‚°ã‹ã‚‰å–å¾—ã™ã‚‹ãŸã‚ä¸è¦ï¼‰
                # self.record_stat("failed")
                
                # ã‚¨ãƒ©ãƒ¼é€šçŸ¥
                self.send_notification(
                    "âŒ Koemojiæ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼",
                    f"ãƒ•ã‚¡ã‚¤ãƒ«: {file_name}\nå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
                )
        
        except Exception as e:
            logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {file_path} - {e}")
            # çµ±è¨ˆã‚’è¨˜éŒ²ï¼ˆãƒ­ã‚°ã‹ã‚‰å–å¾—ã™ã‚‹ãŸã‚ä¸è¦ï¼‰
            # self.record_stat("failed")
            
            # ã‚¨ãƒ©ãƒ¼é€šçŸ¥
            self.send_notification(
                "âŒ Koemojiå‡¦ç†ã‚¨ãƒ©ãƒ¼",
                f"ãƒ•ã‚¡ã‚¤ãƒ«: {os.path.basename(file_path)}\nã‚¨ãƒ©ãƒ¼: {e}"
            )
        finally:
            # å‡¦ç†ä¸­ãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤
            if file_path in self.files_in_process:
                self.files_in_process.remove(file_path)
    
    def transcribe_audio(self, file_path, model_size=None):
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—"""
        try:
            from faster_whisper import WhisperModel
            
            # ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã‚’è¨­å®š
            model_size = model_size or self.config.get("whisper_model", "large")
            compute_type = self.config.get("compute_type", "int8")
            
            # ãƒ¢ãƒ‡ãƒ«ãŒæœªãƒ­ãƒ¼ãƒ‰ã‹è¨­å®šãŒå¤‰ã‚ã£ãŸå ´åˆã®ã¿å†ãƒ­ãƒ¼ãƒ‰
            if (self._whisper_model is None or 
                self._model_config != (model_size, compute_type)):
                logger.info(f"ğŸ§  Whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {model_size}")
                self._whisper_model = WhisperModel(model_size, compute_type=compute_type)
                self._model_config = (model_size, compute_type)
            
            # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
            segments, info = self._whisper_model.transcribe(
                file_path,
                language=self.config.get("language", "ja"),
                beam_size=5,
                best_of=5,
                vad_filter=True
            )
            
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ãƒ†ã‚­ã‚¹ãƒˆã«çµåˆ
            transcription = []
            for segment in segments:
                transcription.append(segment.text.strip())
            
            return "\n".join(transcription)
        
        except Exception as e:
            logger.error(f"âŒ æ–‡å­—èµ·ã“ã—å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return None
    
    def generate_daily_summary_for_date(self, date_obj):
        """æŒ‡å®šæ—¥ã®å‡¦ç†ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        try:
            # æ—¥ä»˜ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            target_date = date_obj.strftime("%Y-%m-%d")
            logger.info(f"ğŸ“Š {target_date}ã®æ—¥æ¬¡ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™")
            
            # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰çµ±è¨ˆã‚’é›†è¨ˆ
            stats = self._collect_stats_from_log(target_date)
            
            if stats is None:
                logger.error("ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")
                return
            
            # å¹³å‡å‡¦ç†æ™‚é–“ã‚’è¨ˆç®—ï¼ˆç¾æ™‚ç‚¹ã§ã¯0ï¼‰
            avg_duration = 0  # æ™‚é–“é›†è¨ˆã¯ä»Šå›ã¯å®Ÿè£…ã—ãªã„
            
            # ã‚µãƒãƒªãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
            summary = (
                f"Koemojiå‡¦ç†ã‚µãƒãƒªãƒ¼ ({target_date})\n"
                f"------------------------\n"
                f"ã‚­ãƒ¥ãƒ¼è¿½åŠ : {stats['queued']}ä»¶\n"
                f"å‡¦ç†å®Œäº†: {stats['processed']}ä»¶\n"
                f"å‡¦ç†å¤±æ•—: {stats['failed']}ä»¶\n"
                f"æ®‹ã‚Šã‚­ãƒ¥ãƒ¼: {len(self.processing_queue)}ä»¶\n"
                f"------------------------\n"
            )
            
            # ãƒ­ã‚°ã«è¨˜éŒ²
            logger.info(summary.replace('\n', ' '))
            
            # ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            summary_dir = "reports"
            os.makedirs(summary_dir, exist_ok=True)
            
            summary_file = os.path.join(summary_dir, f"daily_summary_{target_date}.txt")
            with open(summary_file, 'w', encoding='utf-8') as f:
                f.write(summary)
            
            # é€šçŸ¥é€ä¿¡
            self.send_notification(
                f"ğŸ“Š Koemojiæ—¥æ¬¡ã‚µãƒãƒªãƒ¼ ({target_date})",
                f"å‡¦ç†å®Œäº†: {stats['processed']}ä»¶\n"
                f"å‡¦ç†å¤±æ•—: {stats['failed']}ä»¶\n"
                f"æ®‹ã‚Šã‚­ãƒ¥ãƒ¼: {len(self.processing_queue)}ä»¶"
            )
        
        except Exception as e:
            logger.error(f"âŒ æ—¥æ¬¡ã‚µãƒãƒªãƒ¼ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
    def generate_daily_summary(self):
        """ä»Šæ—¥ã®å‡¦ç†ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆï¼ˆäº’æ›æ€§ã®ãŸã‚æ®‹ã™ï¼‰"""
        self.generate_daily_summary_for_date(datetime.now().date())
    
    def _collect_stats_from_log(self, target_date):
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æŒ‡å®šæ—¥ã®çµ±è¨ˆã‚’é›†è¨ˆ"""
        try:
            stats = {
                "queued": 0,
                "processed": 0,
                "failed": 0,
                "date": target_date
            }
            
            # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã„ã¦èª­ã¿è¾¼ã‚€
            log_path = "koemoji.log"
            if not os.path.exists(log_path):
                return stats  # ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã‘ã‚Œã°ç©ºã®çµ±è¨ˆã‚’è¿”ã™
            
            with open(log_path, 'r', encoding='utf-8') as f:
                for line in f:
                    # æ—¥ä»˜ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
                    if target_date not in line:
                        continue
                    
                    # å„ç¨®ã‚¤ãƒ™ãƒ³ãƒˆã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                    if "â• ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ " in line:
                        stats["queued"] += 1
                    elif "âœ… æ–‡å­—èµ·ã“ã—å®Œäº†" in line:
                        stats["processed"] += 1
                    elif "âŒ æ–‡å­—èµ·ã“ã—å¤±æ•—" in line:
                        stats["failed"] += 1
            
            return stats
            
        except Exception as e:
            logger.error(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return None
    
    def send_notification(self, title, message):
        """é€šçŸ¥ã‚’ãƒ­ã‚°ã«è¨˜éŒ²ã™ã‚‹"""
        logger.info(f"{title} - {message}")
    
    def is_already_running(self):
        """æ—¢ã«å®Ÿè¡Œä¸­ã‹ãƒã‚§ãƒƒã‚¯"""
        current_pid = os.getpid()
        
        for proc in psutil.process_iter(['pid', 'cmdline']):
            try:
                if proc.pid == current_pid:
                    continue
                    
                cmdline = proc.info.get('cmdline')
                if cmdline and len(cmdline) > 1:
                    # Pythonã¾ãŸã¯Python3ãƒ—ãƒ­ã‚»ã‚¹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
                    if 'python' in cmdline[0].lower() or 'python3' in cmdline[0].lower():
                        # main.pyã‚’å®Ÿè¡Œã—ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                        for arg in cmdline[1:]:
                            if arg.endswith('main.py'):
                                logger.debug(f"æ—¢å­˜ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ¤œå‡º: PID={proc.pid}")
                                return True
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                pass
        
        return False
    
    
    def run(self):
        """ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ«ãƒ¼ãƒ—"""
        try:
            # æ—¢ã«å®Ÿè¡Œä¸­ã‹ãƒã‚§ãƒƒã‚¯
            if self.is_already_running():
                logger.error("âš ï¸  æ—¢ã«åˆ¥ã®KoemojiAutoãƒ—ãƒ­ã‚»ã‚¹ãŒå®Ÿè¡Œä¸­ã§ã™ã€‚")
                self.send_notification(
                    "âš ï¸  KoemojiAutoã‚¨ãƒ©ãƒ¼",
                    "æ—¢ã«åˆ¥ã®ãƒ—ãƒ­ã‚»ã‚¹ãŒå®Ÿè¡Œä¸­ã§ã™ã€‚"
                )
                return
            
            logger.info("ğŸš€ KoemojiAutoå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
            
            # é–‹å§‹é€šçŸ¥
            self.send_notification(
                "ğŸ™ï¸ KoemojiAuto",
                "è‡ªå‹•æ–‡å­—èµ·ã“ã—ã‚µãƒ¼ãƒ“ã‚¹ãŒé–‹å§‹ã•ã‚Œã¾ã—ãŸ"
            )
            
            # 24æ™‚é–“ãƒ¢ãƒ¼ãƒ‰ã‹æ™‚é–“åˆ¶é™ãƒ¢ãƒ¼ãƒ‰ã‹ã‚’ç¢ºèª
            continuous_mode = self.config.get("continuous_mode", False)
            if continuous_mode:
                logger.info("â™¾ï¸  24æ™‚é–“é€£ç¶šãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™")
                end_time = None  # 24æ™‚é–“ãƒ¢ãƒ¼ãƒ‰ã§ã¯çµ‚äº†æ™‚åˆ»ã¯ãªã„
            else:
                end_time = self.get_end_time()
                logger.info(f"â° æ™‚é–“åˆ¶é™ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™ï¼ˆçµ‚äº†æ™‚åˆ»: {end_time}ï¼‰")
            
            scan_interval = self.config.get("scan_interval_minutes", 30) * 60  # ç§’ã«å¤‰æ›
            last_scan_time = 0
            last_summary_date = datetime.now().date()  # ç¾åœ¨ã®æ—¥ä»˜ã§åˆæœŸåŒ–
            
            # åˆå›ã‚¹ã‚­ãƒ£ãƒ³
            self.scan_and_queue_files()
            self.process_queued_files()
            
            # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
            while continuous_mode or (end_time and datetime.now().time() < end_time):
                current_time = time.time()
                
                # æ—¥ä»˜ãŒå¤‰ã‚ã£ãŸã‚‰æ–°ã—ã„çµ±è¨ˆã‚¨ãƒ³ãƒˆãƒªã‚’ä½œæˆï¼ˆãƒ­ã‚°ãƒ™ãƒ¼ã‚¹ãªã®ã§ä¸è¦ï¼‰
                # self._ensure_daily_stats()
                
                # å®šæœŸçš„ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³
                if current_time - last_scan_time >= scan_interval:
                    self.scan_and_queue_files()
                    last_scan_time = current_time
                
                # ã‚­ãƒ¥ãƒ¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
                self.process_queued_files()
                
                # æ—¥ä»˜ãŒå¤‰ã‚ã£ãŸã‚‰ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ
                current_date = datetime.now().date()
                if last_summary_date != current_date and last_summary_date is not None:
                    # å‰æ—¥ã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ
                    self.generate_daily_summary_for_date(last_summary_date)
                    last_summary_date = current_date
                
                # çŸ­ã„å¾…æ©Ÿ
                time.sleep(5)
            
            # æ™‚é–“åˆ¶é™ãƒ¢ãƒ¼ãƒ‰ã®çµ‚äº†å‡¦ç†
            if not continuous_mode:
                logger.info("â° å‡¦ç†æ™‚é–“ãŒçµ‚äº†ã—ã¾ã—ãŸ")
                
                # æ—¥æ¬¡ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ
                self.generate_daily_summary()
                
                # çµ‚äº†é€šçŸ¥
                remaining = len(self.processing_queue)
                today = datetime.now().strftime("%Y-%m-%d")
                processed = self.daily_stats.get(today, {}).get("processed", 0)
                
                if remaining > 0:
                    self.send_notification(
                        "â° KoemojiAutoå‡¦ç†çµ‚äº†",
                        f"å‡¦ç†å®Œäº†: {processed}ä»¶\næ®‹ã‚Šã‚­ãƒ¥ãƒ¼: {remaining}ä»¶"
                    )
                else:
                    self.send_notification(
                        "ğŸ‰ KoemojiAutoå‡¦ç†å®Œäº†",
                        f"ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«({processed}ä»¶)ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ"
                    )
            
        except Exception as e:
            logger.error(f"âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        finally:
            logger.info("ğŸ‘‹ KoemojiAutoã‚’çµ‚äº†ã—ã¾ã—ãŸ")


# å®Ÿè¡Œä¾‹
if __name__ == "__main__":
    processor = KoemojiProcessor()
    processor.run()